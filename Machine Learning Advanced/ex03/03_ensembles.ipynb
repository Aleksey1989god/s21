{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 03\n",
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:30.846900Z",
     "start_time": "2025-11-11T17:49:30.005844Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import joblib\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create the same dataframe as in the previous exercise.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test` and then get `X_train`, `y_train`, `X_valid`, `y_valid` from the previous `X_train`, `y_train`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:30.876903Z",
     "start_time": "2025-11-11T17:49:30.850902Z"
    }
   },
   "source": [
    "df = pd.read_csv('../data/day-of-week-not-scaled.csv')\n",
    "df_day = pd.read_csv('../data/dayofweek.csv')\n",
    "df['dayofweek'] = df_day['dayofweek']"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:31.083383Z",
     "start_time": "2025-11-11T17:49:31.068383Z"
    }
   },
   "source": [
    "X = df.drop('dayofweek', axis=1)\n",
    "y = df['dayofweek']"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:31.145383Z",
     "start_time": "2025-11-11T17:49:31.130388Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('dayofweek', axis=1), \n",
    "    df['dayofweek'],\n",
    "    stratify=df['dayofweek'],\n",
    "    test_size=0.2,\n",
    "    random_state=21,\n",
    "    shuffle=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:31.206888Z",
     "start_time": "2025-11-11T17:49:31.192372Z"
    }
   },
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    stratify=y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=21,\n",
    "    shuffle=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Individual classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train SVM, decision tree and random forest again with the best parameters that you got from the 01 exercise with `random_state=21` for all of them.\n",
    "2. Evaluate `accuracy`, `precision`, and `recall` for them on the validation set.\n",
    "3. The result of each cell of the section should look like this:\n",
    "\n",
    "```\n",
    "accuracy is 0.87778\n",
    "precision is 0.88162\n",
    "recall is 0.87778\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:31.639148Z",
     "start_time": "2025-11-11T17:49:31.270891Z"
    }
   },
   "source": [
    "svm = SVC(kernel='rbf', \n",
    "          C=10,\n",
    "          class_weight=None,\n",
    "          gamma='auto',\n",
    "          probability=True,\n",
    "          random_state=21\n",
    "          )\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_valid)\n",
    "svm_model = svm\n",
    "accuracy_svm = accuracy_score(y_valid, y_pred)\n",
    "precision_svm = precision_score(y_valid, y_pred, average='weighted')\n",
    "print(f\"SVM:\")\n",
    "print(f\"accuracy is {accuracy_score(y_valid, y_pred):.5f}\")\n",
    "print(f\"precision is {precision_score(y_valid, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"recall is {recall_score(y_valid, y_pred, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "accuracy is 0.87778\n",
      "precision is 0.88162\n",
      "recall is 0.87778\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:31.798311Z",
     "start_time": "2025-11-11T17:49:31.767311Z"
    }
   },
   "source": [
    "tree = DecisionTreeClassifier(\n",
    "    class_weight='balanced',\n",
    "    criterion='gini',\n",
    "    max_depth=21,\n",
    "    random_state=21\n",
    ")\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_valid)\n",
    "tree_model = tree\n",
    "accuracy_tree = accuracy_score(y_valid, y_pred_tree)\n",
    "precision_tree = precision_score(y_valid, y_pred_tree, average='weighted')\n",
    "print(f\"Decision Tree:\")\n",
    "print(f\"accuracy is {accuracy_score(y_valid, y_pred_tree):.5f}\")\n",
    "print(f\"precision is {precision_score(y_valid, y_pred_tree, average='weighted'):.5f}\")\n",
    "print(f\"recall is {recall_score(y_valid, y_pred_tree, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "accuracy is 0.86667\n",
      "precision is 0.87170\n",
      "recall is 0.86667\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:31.985828Z",
     "start_time": "2025-11-11T17:49:31.816309Z"
    }
   },
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    criterion='entropy',\n",
    "    max_depth=24,\n",
    "    n_estimators=100,\n",
    "    random_state=21\n",
    ")\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rfc = rfc.predict(X_valid)\n",
    "rfc_model = rfc\n",
    "accuracy_rfc = accuracy_score(y_valid, y_pred_rfc)\n",
    "precision_rfc = precision_score(y_valid, y_pred_rfc, average='weighted')\n",
    "print(f\"Random Forest:\")\n",
    "print(f\"accuracy is {accuracy_score(y_valid, y_pred_rfc):.5f}\")\n",
    "print(f\"precision is {precision_score(y_valid, y_pred_rfc, average='weighted'):.5f}\")\n",
    "print(f\"recall is {recall_score(y_valid, y_pred_rfc, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "accuracy is 0.89630\n",
      "precision is 0.89698\n",
      "recall is 0.89630\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Voting classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `VotingClassifier` and the three models that you have just trained, calculate the `accuracy`, `precision`, and `recall` on the validation set.\n",
    "2. Play with the other parameteres.\n",
    "3. Calculate the `accuracy`, `precision` and `recall` on the test set for the model with the best weights in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:39.320972Z",
     "start_time": "2025-11-11T17:49:32.049840Z"
    }
   },
   "source": [
    "voting_params_to_try = [\n",
    "    {'voting': 'hard', 'weights': None},\n",
    "    {'voting': 'soft', 'weights': None},\n",
    "    {'voting': 'hard', 'weights': [1, 1, 1]},\n",
    "    {'voting': 'soft', 'weights': [1, 1, 1]},\n",
    "    {'voting': 'hard', 'weights': [2, 1, 2]},\n",
    "    {'voting': 'soft', 'weights': [2, 1, 2]},\n",
    "    {'voting': 'hard', 'weights': [3, 1, 3]},\n",
    "    {'voting': 'soft', 'weights': [3, 1, 3]},\n",
    "    {'voting': 'hard', 'weights': [4, 1, 4]},\n",
    "    {'voting': 'soft', 'weights': [4, 1, 4]},\n",
    "]\n",
    "\n",
    "best_voting_accuracy = 0\n",
    "best_voting_params = None\n",
    "best_voting_model = None\n",
    "\n",
    "\n",
    "for params in voting_params_to_try:\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('svm', svm),\n",
    "            ('tree', tree),\n",
    "            ('rf', rfc)\n",
    "        ],\n",
    "        voting=params['voting'],\n",
    "        weights=params['weights'],\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    y_pred = voting_clf.predict(X_valid)\n",
    "    \n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    precision = precision_score(y_valid, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"voting: {params['voting']}, weights: {params['weights']}\")\n",
    "    print(f\"accuracy: {accuracy:.5f}, precision: {precision:.5f}\")\n",
    "    \n",
    "    if accuracy > best_voting_accuracy or (accuracy == best_voting_accuracy and precision > best_voting_precision):\n",
    "        best_voting_accuracy = accuracy\n",
    "        best_voting_precision = precision\n",
    "        best_voting_params = params\n",
    "        best_voting_model = voting_clf\n",
    "\n",
    "print(f\"Best parameters: {best_voting_params}\")\n",
    "print(f\"Best accuracy: {best_voting_accuracy:.5f}\")\n",
    "print(f\"Best precision: {best_voting_precision:.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting: hard, weights: None\n",
      "accuracy: 0.90000, precision: 0.89993\n",
      "voting: soft, weights: None\n",
      "accuracy: 0.88519, precision: 0.88840\n",
      "voting: hard, weights: [1, 1, 1]\n",
      "accuracy: 0.90000, precision: 0.89993\n",
      "voting: soft, weights: [1, 1, 1]\n",
      "accuracy: 0.88519, precision: 0.88840\n",
      "voting: hard, weights: [2, 1, 2]\n",
      "accuracy: 0.90000, precision: 0.89993\n",
      "voting: soft, weights: [2, 1, 2]\n",
      "accuracy: 0.90370, precision: 0.90462\n",
      "voting: hard, weights: [3, 1, 3]\n",
      "accuracy: 0.90000, precision: 0.89993\n",
      "voting: soft, weights: [3, 1, 3]\n",
      "accuracy: 0.90370, precision: 0.90364\n",
      "voting: hard, weights: [4, 1, 4]\n",
      "accuracy: 0.90000, precision: 0.89993\n",
      "voting: soft, weights: [4, 1, 4]\n",
      "accuracy: 0.91111, precision: 0.91288\n",
      "Best parameters: {'voting': 'soft', 'weights': [4, 1, 4]}\n",
      "Best accuracy: 0.91111\n",
      "Best precision: 0.91288\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:39.459003Z",
     "start_time": "2025-11-11T17:49:39.398997Z"
    }
   },
   "source": [
    "y_pred_best_voting = best_voting_model.predict(X_valid)\n",
    "recall_best_voting = recall_score(y_valid, y_pred_best_voting, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Best model Voting Classifier:\")\n",
    "print(f\"Parameters: {best_voting_params}\")\n",
    "print(f\"Accuracy: {best_voting_accuracy:.5f}\")\n",
    "print(f\"Precision: {best_voting_precision:.5f}\")\n",
    "print(f\"Recall: {recall_best_voting:.5f}\")\n",
    "\n",
    "y_pred_test_voting = best_voting_model.predict(X_test)\n",
    "accuracy_test_voting = accuracy_score(y_test, y_pred_test_voting)\n",
    "precision_test_voting = precision_score(y_test, y_pred_test_voting, average='weighted')\n",
    "recall_test_voting = recall_score(y_test, y_pred_test_voting, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\nTest sample:\")\n",
    "print(f\"accuracy is {accuracy_test_voting:.5f}\")\n",
    "print(f\"precision is {precision_test_voting:.5f}\")\n",
    "print(f\"recall is {recall_test_voting:.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model Voting Classifier:\n",
      "Parameters: {'voting': 'soft', 'weights': [4, 1, 4]}\n",
      "Accuracy: 0.91111\n",
      "Precision: 0.91288\n",
      "Recall: 0.91111\n",
      "\n",
      "Test sample:\n",
      "accuracy is 0.90533\n",
      "precision is 0.90881\n",
      "recall is 0.90533\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bagging classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `BaggingClassifier` and `SVM` with the best parameters create an ensemble, try different values of the `n_estimators`, use `random_state=21`.\n",
    "2. Play with the other parameters.\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:41.009074Z",
     "start_time": "2025-11-11T17:49:39.537849Z"
    }
   },
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=50, n_jobs=-1, random_state=21)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88462\n",
      "Precision: 0.88941\n",
      "Recall: 0.88462\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:43.619001Z",
     "start_time": "2025-11-11T17:49:41.087082Z"
    }
   },
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=40, n_jobs=-1, random_state=6, bootstrap=False)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88757\n",
      "Precision: 0.88906\n",
      "Recall: 0.88757\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:45.286829Z",
     "start_time": "2025-11-11T17:49:43.697644Z"
    }
   },
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=60, n_jobs=-1, random_state=21, warm_start=True, bootstrap_features=True)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79882\n",
      "Precision: 0.82461\n",
      "Recall: 0.79882\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:46.036767Z",
     "start_time": "2025-11-11T17:49:45.367786Z"
    }
   },
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=20, n_jobs=-1, random_state=15, warm_start=True)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87574\n",
      "Precision: 0.88351\n",
      "Recall: 0.87574\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:50.165635Z",
     "start_time": "2025-11-11T17:49:46.191766Z"
    }
   },
   "source": [
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(C=10, gamma='auto', probability=True, random_state=21, kernel='rbf'),\n",
    "    n_estimators=100, n_jobs=-1, oob_score=True, random_state=50)\n",
    "y_pred = bagging_clf.fit(X_train, y_train).predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.5f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.5f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87574\n",
      "Precision: 0.88161\n",
      "Recall: 0.87574\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:56.816999Z",
     "start_time": "2025-11-11T17:49:50.240755Z"
    }
   },
   "source": [
    "bagging_results = []\n",
    "for n in [5, 10, 25, 50]:\n",
    "    bagging = BaggingClassifier(\n",
    "        SVC(\n",
    "            kernel='rbf',\n",
    "            C=10,\n",
    "            gamma='auto',\n",
    "            class_weight=None,\n",
    "            probability=True,\n",
    "            random_state=21\n",
    "        ),\n",
    "        n_estimators=n,\n",
    "        random_state=21,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    y_pred_bag = bagging.fit(X_train, y_train).predict(X_test)\n",
    "    bagging_results.append({\n",
    "        'n_estimators': n,\n",
    "        'accuracy': accuracy_score(y_test, y_pred_bag),\n",
    "        'precision': precision_score(y_test, y_pred_bag, average='weighted'),\n",
    "        'recall': recall_score(y_test, y_pred_bag, average='weighted'),\n",
    "        'model': bagging\n",
    "    })"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:56.925Z",
     "start_time": "2025-11-11T17:49:56.911Z"
    }
   },
   "source": [
    "best_bagging = sorted(bagging_results, key=lambda x: (x['accuracy'], x['precision']), reverse=True)[0]\n",
    "print(f\"Best model: BaggingClassifier (n_estimators={best_bagging['n_estimators']})\")\n",
    "best_bagging_accuracy = best_bagging['accuracy']\n",
    "best_bagging_precision = best_bagging['precision']\n",
    "print(f\"accuracy is {best_bagging['accuracy']:.5f}\")\n",
    "print(f\"precision is {best_bagging['precision']:.5f}\")\n",
    "print(f\"recall is {best_bagging['recall']:.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: BaggingClassifier (n_estimators=50)\n",
      "accuracy is 0.88462\n",
      "precision is 0.88941\n",
      "recall is 0.88462\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:58.547795Z",
     "start_time": "2025-11-11T17:49:57.005003Z"
    }
   },
   "source": [
    "best_bagging['model'].fit(X_train, y_train)\n",
    "y_pred_bag_test = best_bagging['model'].predict(X_test)\n",
    "best_bagging_model = best_bagging['model']\n",
    "accuracy_test_bagging = accuracy_score(y_test, y_pred_bag_test)\n",
    "precision_test_bagging = precision_score(y_test, y_pred_bag_test, average='weighted')\n",
    "recall_test_bagging = recall_score(y_test, y_pred_bag_test, average='weighted')\n",
    "print(f\"BaggingClassifier (n_estimators={best_bagging['n_estimators']}) test sample:\")\n",
    "print(f\"accuracy is {accuracy_score(y_test, y_pred_bag_test):.5f}\")\n",
    "print(f\"precision is {precision_score(y_test, y_pred_bag_test, average='weighted'):.5f}\")\n",
    "print(f\"recall is {recall_score(y_test, y_pred_bag_test, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier (n_estimators=50) test sample:\n",
      "accuracy is 0.88462\n",
      "precision is 0.88941\n",
      "recall is 0.88462\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To achieve reproducibility in this case you will have to create an object of cross-validation generator: `StratifiedKFold(n_splits=n, shuffle=True, random_state=21)`, where `n` you will try to optimize (the details are below).\n",
    "2. Using `StackingClassifier` and the three models that you have recently trained, calculate the `accuracy`, `precision` and `recall` on the validation set, try different values of `n_splits` `[2, 3, 4, 5, 6, 7]` in the cross-validation generator and parameter `passthrough` in the classifier itself,\n",
    "3. Calculate the `accuracy`, `precision`, and `recall` for the model with the best parameters (in terms of accuracy) on the test set (if there are several of them with equal values, choose the one with the higher precision). Use `final_estimator=LogisticRegression(solver='liblinear')`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:49:58.656324Z",
     "start_time": "2025-11-11T17:49:58.642327Z"
    }
   },
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=21)\n",
    "print(cv)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=21, shuffle=True)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:50:12.972538Z",
     "start_time": "2025-11-11T17:49:58.845324Z"
    }
   },
   "source": [
    "stacking_results = []\n",
    "for n_splits in [2, 3, 4, 5, 6, 7]:\n",
    "    for passthrough in [False, True]:\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "        stacking = StackingClassifier(\n",
    "            estimators=[\n",
    "                ('svm', svm),\n",
    "                ('tree', tree),\n",
    "                ('rf', rfc)\n",
    "            ],\n",
    "            final_estimator=OneVsRestClassifier(LogisticRegression(solver='liblinear')),\n",
    "            cv=cv,\n",
    "            passthrough=passthrough,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        stacking.fit(X_train, y_train)\n",
    "        y_pred_stack = stacking.predict(X_valid)\n",
    "        stacking_results.append({\n",
    "            'n_splits': n_splits,\n",
    "            'passthrough': passthrough,\n",
    "            'accuracy': accuracy_score(y_valid, y_pred_stack),\n",
    "            'precision': precision_score(y_valid, y_pred_stack, average='weighted'),\n",
    "            'recall': recall_score(y_valid, y_pred_stack, average='weighted'),\n",
    "            'model': stacking\n",
    "        })\n",
    "        print(f\"StackingClassifier (n_splits={n_splits}, passthrough={passthrough}):\")\n",
    "        print(f\"accuracy is {accuracy_score(y_valid, y_pred_stack):.5f}\")\n",
    "        print(f\"precision is {precision_score(y_valid, y_pred_stack, average='weighted'):.5f}\")\n",
    "        print(f\"recall is {recall_score(y_valid, y_pred_stack, average='weighted'):.5f}\")\n",
    "        print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier (n_splits=2, passthrough=False):\n",
      "accuracy is 0.89630\n",
      "precision is 0.89678\n",
      "recall is 0.89630\n",
      "\n",
      "StackingClassifier (n_splits=2, passthrough=True):\n",
      "accuracy is 0.90370\n",
      "precision is 0.90619\n",
      "recall is 0.90370\n",
      "\n",
      "StackingClassifier (n_splits=3, passthrough=False):\n",
      "accuracy is 0.89630\n",
      "precision is 0.89759\n",
      "recall is 0.89630\n",
      "\n",
      "StackingClassifier (n_splits=3, passthrough=True):\n",
      "accuracy is 0.90370\n",
      "precision is 0.90632\n",
      "recall is 0.90370\n",
      "\n",
      "StackingClassifier (n_splits=4, passthrough=False):\n",
      "accuracy is 0.90370\n",
      "precision is 0.90570\n",
      "recall is 0.90370\n",
      "\n",
      "StackingClassifier (n_splits=4, passthrough=True):\n",
      "accuracy is 0.91111\n",
      "precision is 0.91327\n",
      "recall is 0.91111\n",
      "\n",
      "StackingClassifier (n_splits=5, passthrough=False):\n",
      "accuracy is 0.90000\n",
      "precision is 0.90056\n",
      "recall is 0.90000\n",
      "\n",
      "StackingClassifier (n_splits=5, passthrough=True):\n",
      "accuracy is 0.90000\n",
      "precision is 0.90217\n",
      "recall is 0.90000\n",
      "\n",
      "StackingClassifier (n_splits=6, passthrough=False):\n",
      "accuracy is 0.90370\n",
      "precision is 0.90436\n",
      "recall is 0.90370\n",
      "\n",
      "StackingClassifier (n_splits=6, passthrough=True):\n",
      "accuracy is 0.90370\n",
      "precision is 0.90450\n",
      "recall is 0.90370\n",
      "\n",
      "StackingClassifier (n_splits=7, passthrough=False):\n",
      "accuracy is 0.90370\n",
      "precision is 0.90538\n",
      "recall is 0.90370\n",
      "\n",
      "StackingClassifier (n_splits=7, passthrough=True):\n",
      "accuracy is 0.90370\n",
      "precision is 0.90640\n",
      "recall is 0.90370\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:50:12.988536Z",
     "start_time": "2025-11-11T17:50:12.980538Z"
    }
   },
   "source": [
    "best_stack = sorted(stacking_results, key=lambda x: (x['accuracy'], x['precision']), reverse=True)[0]\n",
    "print(f\"Лучшая модель: StackingClassifier (n_splits={best_stack['n_splits']}, passthrough={best_stack['passthrough']})\")\n",
    "best_stacking_accuracy = best_stack['accuracy']\n",
    "best_stacking_precision = best_stack['precision']\n",
    "print(f\"accuracy is {best_stack['accuracy']:.5f}\")\n",
    "print(f\"precision is {best_stack['precision']:.5f}\")\n",
    "print(f\"recall is {best_stack['recall']:.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель: StackingClassifier (n_splits=4, passthrough=True)\n",
      "accuracy is 0.91111\n",
      "precision is 0.91327\n",
      "recall is 0.91111\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:50:14.174183Z",
     "start_time": "2025-11-11T17:50:13.116105Z"
    }
   },
   "source": [
    "best_stack['model'].fit(X_train, y_train)\n",
    "y_pred_stack_test = best_stack['model'].predict(X_test)\n",
    "best_stacking_model = best_stack['model']\n",
    "accuracy_test_stacking = accuracy_score(y_test, y_pred_stack_test)\n",
    "precision_test_stacking = precision_score(y_test, y_pred_stack_test, average='weighted')\n",
    "recall_test_stacking = recall_score(y_test, y_pred_stack_test, average='weighted')\n",
    "print(f\"StackingClassifier (n_splits={best_stack['n_splits']}, passthrough={best_stack['passthrough']}) на тестовой выборке:\")\n",
    "print(f\"accuracy is {accuracy_score(y_test, y_pred_stack_test):.5f}\")\n",
    "print(f\"precision is {precision_score(y_test, y_pred_stack_test, average='weighted'):.5f}\")\n",
    "print(f\"recall is {recall_score(y_test, y_pred_stack_test, average='weighted'):.5f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier (n_splits=4, passthrough=True) на тестовой выборке:\n",
      "accuracy is 0.90533\n",
      "precision is 0.90844\n",
      "recall is 0.90533\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model in terms of accuracy (if there are several of them with equal values, choose the one with the higher precision).\n",
    "2. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your full dataset), for which labname and for which users.\n",
    "3. Save the model."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:50:14.361182Z",
     "start_time": "2025-11-11T17:50:14.316182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models_comparison = {\n",
    "    'SVM': {'accuracy': accuracy_svm, 'precision': precision_svm},\n",
    "    'Decision Tree': {'accuracy': accuracy_tree, 'precision': precision_tree},\n",
    "    'Random Forest': {'accuracy': accuracy_rfc, 'precision': precision_rfc},\n",
    "    'Voting Classifier': {'accuracy': best_voting_accuracy, 'precision': best_voting_precision},\n",
    "    'Bagging Classifier': {'accuracy': best_bagging_accuracy, 'precision': best_bagging_precision},\n",
    "    'Stacking Classifier': {'accuracy': best_stacking_accuracy, 'precision': best_stacking_precision}\n",
    "}\n",
    "\n",
    "best_model_name = None\n",
    "best_accuracy = 0\n",
    "best_precision = 0\n",
    "\n",
    "for model_name, metrics in models_comparison.items():\n",
    "    if (metrics['accuracy'] > best_accuracy or \n",
    "        (metrics['accuracy'] == best_accuracy and metrics['precision'] > best_precision)):\n",
    "        best_accuracy = metrics['accuracy']\n",
    "        best_precision = metrics['precision']\n",
    "        best_model_name = model_name\n",
    "\n",
    "\n",
    "print(f\"Best model name: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_accuracy:.5f}\")\n",
    "print(f\"Precision: {best_precision:.5f}\")\n",
    "\n",
    "\n",
    "models_comparison_test = {\n",
    "    'Voting Classifier': {'accuracy': accuracy_test_voting, 'precision': precision_test_voting, 'recall': recall_test_voting},\n",
    "    'Bagging Classifier': {'accuracy': accuracy_test_bagging, 'precision': precision_test_bagging, 'recall': recall_test_bagging},\n",
    "    'Stacking Classifier': {'accuracy': accuracy_test_stacking, 'precision': precision_test_stacking, 'recall': recall_test_stacking}\n",
    "}\n",
    "\n",
    "best_model_name = None\n",
    "best_accuracy = 0\n",
    "best_precision = 0\n",
    "\n",
    "for model_name, metrics in models_comparison_test.items():\n",
    "    if (metrics['accuracy'] > best_accuracy or \n",
    "        (metrics['accuracy'] == best_accuracy and metrics['precision'] > best_precision)):\n",
    "        best_accuracy = metrics['accuracy']\n",
    "        best_precision = metrics['precision']\n",
    "        best_recall = metrics['recall']\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f\"Best model name test sample:{best_model_name}\")\n",
    "print(f\"accuracy is {best_accuracy:.5f}\")\n",
    "print(f\"precision is {best_precision:.5f}\")\n",
    "print(f\"recall is {best_recall:.5f}\")\n",
    "\n",
    "if best_model_name == 'SVM':\n",
    "    best_model = svm_model\n",
    "elif best_model_name == 'Decision Tree':\n",
    "    best_model = tree_model\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = rfc_model\n",
    "elif best_model_name == 'Voting Classifier':\n",
    "    best_model = best_voting_model\n",
    "elif best_model_name == 'Bagging Classifier':\n",
    "    best_model = best_bagging_model\n",
    "else:  \n",
    "    best_model = best_stacking_model\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "precision_best = precision_score(y_test, y_pred_best, average='weighted', zero_division=0)\n",
    "recall_best = recall_score(y_test, y_pred_best, average='weighted', zero_division=0)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model name: Stacking Classifier\n",
      "Accuracy: 0.91111\n",
      "Precision: 0.91327\n",
      "Best model name test sample:Voting Classifier\n",
      "accuracy is 0.90533\n",
      "precision is 0.90881\n",
      "recall is 0.90533\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:50:14.516744Z",
     "start_time": "2025-11-11T17:50:14.503744Z"
    }
   },
   "source": [
    "print(\" Day |  All  |  Error | % Error\")\n",
    "error_rates_day = []\n",
    "for day in range(7):\n",
    "    day_mask = y_test == day\n",
    "    total_samples = np.sum(day_mask)\n",
    "    wrong_predictions = np.sum(y_pred_best[day_mask] != day)\n",
    "    error_rate = wrong_predictions / total_samples if total_samples > 0 else 0\n",
    "    error_rates_day.append(error_rate)\n",
    "    print(f\"{day:4} | {total_samples:5} | {wrong_predictions:6} | {error_rate:.3f}\")\n",
    "\n",
    "worst_day = np.argmax(error_rates_day)\n",
    "print(f\"error rates day {worst_day} ({error_rates_day[worst_day]:.3f} error)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Day |  All  |  Error | % Error\n",
      "   0 |    27 |      8 | 0.296\n",
      "   1 |    55 |      4 | 0.073\n",
      "   2 |    30 |      2 | 0.067\n",
      "   3 |    80 |      3 | 0.037\n",
      "   4 |    21 |      2 | 0.095\n",
      "   5 |    54 |      7 | 0.130\n",
      "   6 |    71 |      6 | 0.085\n",
      "error rates day 0 (0.296 error)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:50:14.672782Z",
     "start_time": "2025-11-11T17:50:14.659783Z"
    }
   },
   "source": [
    "labname_columns = [col for col in X.columns if col.startswith('labname_')]\n",
    "labname_errors = []\n",
    "\n",
    "for lab_col in labname_columns:\n",
    "    lab_mask = X_test[lab_col] == 1\n",
    "    if lab_mask.sum() > 0:\n",
    "        total_with_lab = lab_mask.sum()\n",
    "        wrong_with_lab = np.sum(y_pred_best[lab_mask] != y_test[lab_mask])\n",
    "        error_rate = wrong_with_lab / total_with_lab\n",
    "        \n",
    "        labname_errors.append({\n",
    "            'labname': lab_col,\n",
    "            'total_samples': total_with_lab,\n",
    "            'wrong_predictions': wrong_with_lab,\n",
    "            'error_rate': error_rate\n",
    "        })\n",
    "\n",
    "labname_errors_sorted = sorted(labname_errors, key=lambda x: x['error_rate'], reverse=True)\n",
    "\n",
    "print(\"Labname |  All  |  Error | % Error\")\n",
    "for lab in labname_errors_sorted[:5]:\n",
    "    lab_short = lab['labname'].replace('labname_', '')[:15]\n",
    "    print(f\"{lab_short:7} | {lab['total_samples']:5} | {lab['wrong_predictions']:6} | {lab['error_rate']:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labname |  All  |  Error | % Error\n",
      "lab03   |     1 |      1 | 1.000\n",
      "laba04  |    35 |      9 | 0.257\n",
      "laba04s |    25 |      6 | 0.240\n",
      "lab05s  |     6 |      1 | 0.167\n",
      "laba06  |     9 |      1 | 0.111\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:50:14.844833Z",
     "start_time": "2025-11-11T17:50:14.813810Z"
    }
   },
   "source": [
    "user_columns = [col for col in X.columns if col.startswith('uid_user_')]\n",
    "user_errors = []\n",
    "\n",
    "for user_col in user_columns:\n",
    "    user_mask = X_test[user_col] == 1\n",
    "    total_with_user = user_mask.sum()\n",
    "    if total_with_user > 0:\n",
    "        wrong_with_user = np.sum(y_pred_best[user_mask] != y_test[user_mask])\n",
    "        error_rate = wrong_with_user / total_with_user\n",
    "        \n",
    "        user_errors.append({\n",
    "            'user': user_col.replace('uid_user_', ''),\n",
    "            'total_samples': total_with_user,\n",
    "            'wrong_predictions': wrong_with_user,\n",
    "            'error_rate': error_rate\n",
    "        })\n",
    "\n",
    "user_errors_sorted = sorted(user_errors, key=lambda x: x['error_rate'], reverse=True)\n",
    "\n",
    "\n",
    "print(f\"User{' ':8}   | {'All':>6} | {'Errors':>6} | {'% Errors':>8}\")\n",
    "for user in user_errors_sorted[:10]:\n",
    "    print(f\"{user['user']:14} | {user['total_samples']:6} | {user['wrong_predictions']:6} | {user['error_rate']:8.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User           |    All | Errors | % Errors\n",
      "6              |      4 |      2 |    0.500\n",
      "17             |      7 |      2 |    0.286\n",
      "3              |     14 |      3 |    0.214\n",
      "16             |      5 |      1 |    0.200\n",
      "18             |      6 |      1 |    0.167\n",
      "27             |      6 |      1 |    0.167\n",
      "19             |     19 |      3 |    0.158\n",
      "2              |     28 |      4 |    0.143\n",
      "30             |      8 |      1 |    0.125\n",
      "13             |     17 |      2 |    0.118\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T17:50:15.079342Z",
     "start_time": "2025-11-11T17:50:14.988344Z"
    }
   },
   "source": "joblib.dump(best_model, '../data/best_ensemble_model.joblib')",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/best_ensemble_model.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
